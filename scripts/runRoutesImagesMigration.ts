import pg from 'pg'
import dotenv from 'dotenv'
import fs from 'fs'
import path from 'path'
import { fileURLToPath } from 'url'

dotenv.config()

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const dbUrl = process.env.DATABASE_URL

if (!dbUrl) {
  console.error('âŒ é”™è¯¯: æœªæ‰¾åˆ° DATABASE_URL ç¯å¢ƒå˜é‡ã€‚')
  process.exit(1)
}

const pool = new pg.Pool({
  connectionString: dbUrl,
  ssl: {
    rejectUnauthorized: false
  }
})

async function runRoutesImagesMigration() {
  const client = await pool.connect()
  try {
    console.log('ğŸ”Œ æ­£åœ¨è¿æ¥æ•°æ®åº“...')
    
    // è¯»å–è·¯çº¿å›¾ç‰‡å­—æ®µè¿ç§»æ–‡ä»¶
    const sqlPath = path.join(__dirname, '../supabase/migrations/20251228_add_routes_images.sql')
    const sql = fs.readFileSync(sqlPath, 'utf8')

    console.log('ğŸš€ å¼€å§‹æ‰§è¡Œè·¯çº¿å›¾ç‰‡å­—æ®µè¿ç§»...')
    await client.query(sql)
    
    console.log('âœ… è·¯çº¿å›¾ç‰‡å­—æ®µè¿ç§»æˆåŠŸï¼')
    
    // éªŒè¯å­—æ®µæ˜¯å¦æ·»åŠ æˆåŠŸ
    const result = await client.query(`
      SELECT column_name, data_type 
      FROM information_schema.columns 
      WHERE table_schema = 'public' 
      AND table_name = 'routes' 
      AND column_name = 'images'
    `)
    
    if (result.rows.length > 0) {
      console.log(`âœ… ç¡®è®¤: images å­—æ®µå·²æˆåŠŸæ·»åŠ  (ç±»å‹: ${result.rows[0].data_type})`)
    } else {
      console.log('âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° images å­—æ®µ')
    }
    
  } catch (err) {
    console.error('âŒ è·¯çº¿å›¾ç‰‡å­—æ®µè¿ç§»å¤±è´¥:', err)
  } finally {
    client.release()
    await pool.end()
  }
}

runRoutesImagesMigration()